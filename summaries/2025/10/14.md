# Activity Summary for 10/14/2025

## 10:38:44 AM

The logs indicate development activity across two Python files within a project structured around a Raspberry Pi server and an image vision component.

**File-Specific Updates and Significant Timestamps:**

1.  **`c:\Users\zhiha\MDP_Shared\MDP-Maxxing\RPI_Server\Week9.py`**
    *   **Timestamp Range:** 10/14/2025, 9:58:18 AM to 10/14/2025, 10:12:02 AM
    *   **Summary:** Across all recorded entries for this file, the provided code snippet remains identical. This segment defines the `RaspberryPi` class, handling core functionalities like camera control, STM (microcontroller) communication, and Android device interaction. Key methods include `start`, `stop`, `send_and_wait` for STM commands, and `android_io_process` for managing Android communication threads (`recv_android`, `send_android`). It also includes `rpi_queue_listener` and `stm_queue_listener` for processing commands and image capture/object detection logic (`take_snapshot`, image upload to `IMAGE_SERVER`). The snippet ends abruptly, making it unclear if changes occurred in other parts of the file not included in the log.

2.  **`c:\Users\zhiha\MDP_Shared\MDP-Maxxing\RPI_Vision\server_receive_image.py`**
    *   **Initial State (10/14/2025, 10:00:35 AM):** The image recognition server processes uploaded images. It uses `cv2.imdecode` for faster image loading, predicts labels using a model with a confidence threshold (`conf=0.75`), draws bounding boxes if detections are found, and saves both the raw uploaded image to an `uploads` folder and annotated images (or raw if no detection) to a `results` folder.
    *   **Significant Change (10/14/2025, 10:00:43 AM):** The confidence threshold for image prediction (`conf`) was lowered from `0.75` to `0.25`. This change suggests an attempt to make the object detection more sensitive, potentially to catch more objects, even if with lower confidence.
    *   **Significant Change (10/14/2025, 10:04:27 AM):** The code responsible for saving the original raw image to the `UPLOAD_FOLDER` was commented out. This indicates an optimization or change in storage policy, where only the results (annotated or raw if no detection) are saved to the `RESULTS_FOLDER`, potentially to save disk space or streamline the workflow.
    *   **Final State (10/14/2025, 10:04:52 AM):** The code remains consistent with the changes made at 10:04:27 AM, maintaining the `0.25` confidence threshold and not saving raw uploads to the `UPLOAD_FOLDER`.

**Patterns and Recurring Elements:**

*   **Focus on Image Processing and Communication:** Both files are integral to a system that captures images from a Raspberry Pi, sends them to a vision server for processing, and communicates results back to an Android device and an STM microcontroller.
*   **Optimization Attempts:** The `server_receive_image.py` file shows direct attempts at optimizing the image processing pipeline by adjusting the confidence threshold for object detection and by removing the redundant saving of raw uploaded images, likely to improve performance or resource usage.
*   **Modularity:** The system is designed with distinct components for hardware interaction (Raspberry Pi server), image recognition (vision server), and communication (AndroidLink, STMLink).
*   **Error Handling and Logging:** Both files extensively use logging (`self.logger.info`, `self.logger.debug`, `self.logger.error`) and include `try-except` blocks for robust operation and debugging.
*   **Asynchronous Operations:** The `Week9.py` file utilizes `threading` and `multiprocessing.Process` for concurrent operations (e.g., Android I/O, STM receiving, RPI/STM queue listeners), indicating a responsive, event-driven architecture.

## 12:38:41 PM
The provided log primarily details changes to a single file: `c:\Users\zhiha\MDP_Shared\MDP-Maxxing\RPI_Vision\server_receive_image.py`. This Flask-based Python server is designed for image recognition, handling image uploads, processing them, and storing results.

**File-Specific Updates:**

*   **`c:\Users\zhiha\MDP_Shared\MDP-Maxxing\RPI_Vision\server_receive_image.py`**:
    *   This file defines a Flask application with endpoints such as `/status`, `/upload`, `/retrieve_annotations`, and `/stitch_images`.
    *   The `/upload` endpoint is central, responsible for receiving an image, decoding it using OpenCV (`cv2.imdecode`), predicting labels using a loaded model (`predict_image_labels`), drawing bounding boxes, and saving either annotated or raw images to a `results` folder.
    *   The initial version at **10/14/2025, 12:22:27 PM** used `time.time()` for measuring the total execution time of the `/upload` endpoint. It also contained commented-out code for PIL-based image processing, indicating a prior shift to an OpenCV-based workflow for speed.
    *   The entry at **10/14/2025, 12:22:36 PM** shows no functional changes; the code is identical to the previous timestamp.
    *   A significant update occurred at **10/14/2025, 12:23:18 PM**, where the performance timing mechanism within the `/upload` endpoint was changed from `time.time()` to `time.perf_counter()` for more precise measurements.
    *   Further refinement was made at **10/14/2025, 12:27:15 PM**. This update introduced granular performance logging within the `/upload` function, specifically timing the image decoding (`cv2.imdecode`), prediction (`predict_image_labels`), and result saving stages. The output now includes a detailed breakdown of these individual step times in seconds.

**Timestamps of Significant Changes:**

*   **10/14/2025, 12:23:18 PM**: Switched to `time.perf_counter()` for more accurate performance measurement.
*   **10/14/2025, 12:27:15 PM**: Implemented detailed step-by-step timing within the image processing pipeline, logging decode, predict, and save times individually.

**Patterns or Recurring Elements:**

A clear pattern throughout these changes is a strong emphasis on **performance optimization and precise measurement** within the image recognition pipeline. This is evidenced by:
1.  The initial commented-out PIL code, explicitly mentioning "test new workflow to speed up image rec pipeline."
2.  The subsequent switch from `time.time()` to the higher-resolution `time.perf_counter()`.
3.  The final introduction of granular timing for specific stages (decode, predict, save) to pinpoint bottlenecks and provide actionable performance insights. The repeated "INFO" logs related to timing also underscore this focus.

## 5:15:35 PM
The `Week9.py` file, serving as the Raspberry Pi server's core logic, underwent continuous development throughout the log, primarily focusing on communication with Android and a microcontroller (STM), and integrating an image recognition pipeline. A new file, `server_receive_image.py`, was introduced later, dedicated to handling the image recognition aspect as a separate server.

### File-specific Updates and Timestamps:

**`c:\Users\zhiha\MDP_Shared\MDP-Maxxing\RPI_Server\Week9.py`**

*   **10/14/2025, 2:42:13 PM**: The initial state shows a `RaspberryPi` class managing various links (Android, STM) and queues. It includes methods for starting/stopping hardware (camera, STM link) and listeners. The `stm_queue_listener` method contains logic to capture images (`"SNAPS"` command), send them to an `IMAGE_SERVER`, process detection results (checking for integer labels `38` for right, `39` for left), and send corresponding commands (`"<RIGHT>"`, `"<LEFTS>"`) back to STM. The `send_and_wait` method is designed to wait for "RECEIVED" and "DONE" signals from STM.
*   **10/14/2025, 2:42:59 PM**: An update to `stm_queue_listener` introduced a conditional execution for `self.send_and_wait(command)` for non-"SNAPS" commands. However, it also introduced a syntax error in the `if command == "SNAPS" and :` condition.
*   **10/14/2025, 2:43:33 PM**: The syntax error in the `stm_queue_listener`'s "SNAPS" condition was corrected to `if command == "SNAPS":`.
*   **10/14/2025, 2:44:08 PM**: The `send_and_wait` call for non-"SNAPS" commands within `stm_queue_listener` was commented out, effectively disabling the sending of general STM commands.
*   **10/14/2025, 3:16:40 PM**: A significant change occurred in the `send_and_wait` method. The entire logic for waiting on `stm_received` and `stm_done` events was commented out. This simplified `send_and_wait` to essentially just send the command and return `True` (unless the initial send fails), removing its acknowledgment-waiting capability.
*   **10/14/2025, 3:21:04 PM**: The processing of non-"SNAPS" commands in `stm_queue_listener` was re-enabled and refined. If `send_and_wait` is successful, the command is removed from `self.stm_queue`.
*   **10/14/2025, 3:21:23 PM**: A minor correction was made in `stm_queue_listener`, changing `self.stm_queue.pop()` to `self.stm_queue.pop(0)` to explicitly remove the first item from the queue.
*   **10/14/2025, 4:15:22 PM**: The object detection label comparison logic within `stm_queue_listener` was updated. Instead of comparing `data['label']` with integers (`38`, `39`), it now compares with strings (`'38'`, `'39'`). This indicates a change in the expected data type for labels received from the image recognition server.
*   **10/14/2025, 4:17:39 PM**: No functional changes were observed, likely a save.
*   **10/14/2025, 4:18:45 PM**: Further refinement in `stm_queue_listener`'s "SNAPS" handling. After an image is processed and a potential command is sent based on detection (right arrow, left arrow, or no arrow), `self.stm_queue.pop(0)` is explicitly called to remove the "SNAPS" command from the queue, ensuring progression whether an arrow is detected or not.
*   **10/14/2025, 4:35:05 PM** and **10/14/2025, 4:35:18 PM**: No functional changes, likely saves.

**`c:\Users\zhiha\MDP_Shared\MDP-Maxxing\RPI_Vision_V2\server_receive_image.py`**

*   **10/14/2025, 4:16:44 PM**: This file was introduced as a Flask server for image recognition. It defines:
    *   A `/status` endpoint to check server health.
    *   An `/upload` endpoint that receives an image file, decodes it using `cv2.imdecode` for efficiency, runs `predict_image_labels` for object detection, and if a detection is made, annotates the image using `draw_bounding_box` and saves it. It returns a JSON response including `status`, `annotated` flag, and the `label` (as a string).
    *   Includes placeholder `TODO` routes for `retrieve_annotations` and `stitch_images`.
    *   It defines `UPLOAD_FOLDER` and `RESULTS_FOLDER` for storing images.
    *   The server logs performance metrics for decode, predict, and save operations.

### Patterns and Recurring Elements:

*   **Queue-based Communication**: Both `rpi_action_queue` and `stm_queue` are consistently used for managing commands and actions within the `RaspberryPi` class, illustrating a threaded/multi-process architecture for command handling.
*   **Event-driven Synchronization**: `threading.Event` and `multiprocessing.Event` (e.g., `stm_done`, `stm_received`, `android_stop_event`) are used for synchronization between different threads and processes.
*   **Modular Architecture**: The `RaspberryPi` class encapsulates various hardware and communication components (camera, STM link, Android link, logger). The introduction of `server_receive_image.py` further modularizes the image recognition logic into a separate service.
*   **Logging**: `self.logger.info`, `self.logger.debug`, and `self.logger.error` are extensively used across the codebase for tracking operations and debugging.
*   **Image Recognition Workflow**: A recurring pattern involves capturing an image, sending it to an external server (`IMAGE_SERVER`), receiving detection results, and reacting based on detected labels.
*   **Error Handling and Retries**: `try-except` blocks are common for handling connection errors, JSON decoding issues, and image processing failures. Specifically, in `Week9.py`, there's a retry mechanism for "SNAPS" commands if image capture or upload fails.
*   **Evolution of Command Processing**: The `stm_queue_listener` in `Week9.py` shows a clear evolution, initially attempting to wait for STM acknowledgments, then temporarily disabling general command sending, and finally refining the command sending and queue management logic. The shift from integer to string labels for image recognition results highlights an adaptation to external API changes.